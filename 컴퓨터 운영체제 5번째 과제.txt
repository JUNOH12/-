컴퓨터 운영체제 과제 20220542 성준오


문제 1 (모든 스레드가 시간 0에 도착한 상황)

| 스레드 | 실행 시간(ms) | 우선순위(숫자가 클수록 높음) |
|--------|----------------|-------------------------------|
| T1     | 2              | 2                             |
| T2     | 3              | 1                             |
| T3     | 8              | 4                             |
| T4     | 1              | 2                             |
| T5     | 4              | 3                             |

---

(1) FCFS, SJF, Non-Preemptive Priority 스케줄링 각각의 평균 대기 시간 계산
 FCFS (First Come First Serve)
순서: T1 → T2 → T3 → T4 → T5  
각 스레드의 대기 시간:
- T1: 0  
- T2: 2  
- T3: 2 + 3 = 5  
- T4: 5 + 8 = 13  
- T5: 13 + 1 = 14  

 평균 대기 시간 = (0 + 2 + 5 + 13 + 14) / 5 = 6.8ms


  SJF (Shortest Job First)
실행 시간 기준 정렬: T4(1) → T1(2) → T2(3) → T5(4) → T3(8)  
대기 시간:
- T4: 0  
- T1: 1  
- T2: 1 + 2 = 3  
- T5: 3 + 3 = 6  
- T3: 6 + 4 = 10  

 평균 대기 시간 = (0 + 1 + 3 + 6 + 10) / 5 = 4ms



 Non-Preemptive Priority (우선순위 기준, 숫자가 클수록 높음)
우선순위 순서: T3(4) → T5(3) → T1(2) → T4(2) → T2(1)  
우선순위 같을 경우 먼저 도착한 순서로 (T1, T4 중 T1 우선)

실행 순서: T3 → T5 → T1 → T4 → T2  
대기 시간:
- T3: 0  
- T5: 8  
- T1: 8 + 4 = 12  
- T4: 12 + 2 = 14  
- T2: 14 + 1 = 15  

 평균 대기 시간 = (0 + 8 + 12 + 14 + 15) / 5 = 9.8ms
 (2) RR (Time Quantum = 2ms)  
Gantt 차트를 그려야 하며, 시간마다 다음처럼 처리됨:

순서: T1(2) → T2(2) → T3(2) → T4(1) → T5(2) → T2(1) → T3(2) → T5(2) → T3(2) → T5(…) → T3(2)


RR 알고리즘은 스레드들에게 공평한 실행 기회를 주기 위해 큐에 대기 중인 스레드들을 타임 슬라이스 주기로 돌아가며 선택한다. 따라서 2ms 간격으로 스레드들을 돌아가며 선택하여 실행한다. 이때 평균 대기 시간은 6.6ms이다.



---

 (3) RR에서 컨텍스트 스위칭 오버헤드 포함 시
오버헤드 = 0.1ms, 컨텍스트 스위칭은 스레드 전환마다 발생  
스레드 전환 횟수 = 위 Gantt 차트에서 스레드가 바뀐 횟수 (예: 10회)

한 스레드에서 다음 스레드로 전환할 때마다 오버헤드를 추가해야 한다. 실행 시작 시나 마지막 스레드가 완료된 후에는 컨텍스트 전환이 필요하지 않으므로 오버헤드가 추가되지 않는다. 따라서 실행 시각 2, 4, 6, 7, 9, 10, 12, 14에 총 8회의 오버헤드가 추가되므로 총 걸린 시간은 스레드 실행 시간인 18ms에 0.8ms를 더한 값인 18.8ms가 된다.





## 문제 2 풀이

### (1) FCFS, SJF, Non-Preemptive Priority 평균 대기 시간

**1. FCFS**

도착 순서: T1(0), T2(0), T3(0), T4(1), T5(9)  
T1 → T2 → T3 → T4 → T5 순서로 실행

- T1 대기 시간: 0  
- T2 대기 시간: 4  
- T3 대기 시간: 7  
- T4 대기 시간: 15 - 1 = 14  
- T5 대기 시간: 7

평균 대기 시간 = (0 + 4 + 7 + 14 + 7) / 5 = 6.4ms

---

**2. SJF (Shortest Job First)**

처음 도착한 프로세스 중 실행 시간이 가장 짧은 것부터 실행.  
도중에 도착하는 프로세스도 고려.

실행 순서: T2(3) → T4(1) → T1(4) → T3(8) → T5(5)

- T2 대기 시간: 0  
- T4 대기 시간: 3 - 1 = 2  
- T1 대기 시간: 4  
- T3 대기 시간: 8  
- T5 대기 시간: 16 - 9 = 7  

평균 대기 시간 = (0 + 2 + 4 + 8 + 7) / 5 = 4.2ms

---

**3. Non-Preemptive Priority**

우선순위가 높은 순서대로 실행. 도착 시간도 고려.  
T5(4) > T1(3) > T2(2) > T3(1) = T4(1)

실행 순서: T1 → T2 → T4 → T3 → T5

- T1 대기 시간: 0  
- T2 대기 시간: 4  
- T4 대기 시간: 6  
- T3 대기 시간: 8  
- T5 대기 시간: 16 - 9 = 7  

평균 대기 시간 = (0 + 4 + 6 + 8 + 7) / 5 = 5.0ms

---

### (2) SRTF (선점형, 실행시간 짧은 것부터) 

실시간으로 도착한 프로세스 중 가장 **남은 시간이 짧은** 것부터 실행

실행 순서: T2(0~3) → T4(3~4) → T1(4~8) → T3(8~16) → T5(16~21)

- T2 대기 시간: 0  
- T4 대기 시간: 2  
- T1 대기 시간: 4  
- T3 대기 시간: 8  
- T5 대기 시간: 7  

평균 대기 시간 = (0 + 2 + 4 + 8 + 7) / 5 = 4.2ms

---

### (3) Preemptive Priority (우선순위 + 선점형)

도중에 더 높은 우선순위의 프로세스가 오면 선점.

실행 순서: T1 → T2 → T4 → T3 → T5

- T1 대기 시간: 0  
- T2 대기 시간: 4  
- T4 대기 시간: 6  
- T3 대기 시간: 7  
- T5 대기 시간: 6  

평균 대기 시간 = (0 + 4 + 6 + 7 + 6) / 5 = 4.6ms

---

## 최종 요약

| 스케줄링 방식             | 평균 대기 시간 (ms) |
|--------------------------|----------------------|
| FCFS                     | 8.2                  |
| SJF                      | 4.2                  |
| Non-Preemptive Priority  | 5.0                  |
| SRTF                     | 4.2                  |
| Preemptive Priority      | 4.6                  |


문제 27 해설
문제에서는 리눅스 CFS 스케줄러에서 프로세스 p의 가상 실행 시간(v_r) 계산 방식을 보여주고, 가상 실행 시간이 작을수록 스케줄링 기회를 더 많이 얻는 이유에 해당하지 않는 것을 고르라고 한다.
 * ① 프로세스 p가 타임 슬라이스 내에서 실제 실행한 시간(actual_run_time)이 작을수록 CPU를 사용할 기회를 더 많이 주기 위해: 이는 맞는 이유이다. 실제 실행 시간이 짧을수록 가상 실행 시간이 작아지고, CFS는 가상 실행 시간이 작은 프로세스에게 우선적으로 CPU를 할당하여 공정성을 유지한다.
 * ② 높은 순위의 프로세스에게 CPU를 사용할 기회를 더 많이 주기 위해: 이는 맞는 이유이다. 프로세스 우선순위는 weight_p 값에 반영된다. 높은 우선순위의 프로세스는 더 큰 weight_p 값을 가지므로, 동일한 실제 실행 시간 동안 가상 실행 시간 증가폭이 작아져 더 많은 CPU 시간을 할당받게 된다.
 * ③ 프로세스의 기아 현상을 없애기 위해: 이는 맞는 이유이다. CFS는 가상 실행 시간이 가장 작은 프로세스를 우선적으로 선택함으로써 특정 프로세스가 CPU를 독점하여 다른 프로세스가 실행되지 못하는 기아 현상을 방지한다.
 * ④ CPU 집중 프로세스를 I/O 집중 프로세스보다 더 자주 스케줄하기 위해: 이는 틀린 이유이다. CFS의 주된 목표는 프로세스의 종류(CPU 집중, I/O 집중)에 따른 차별적인 스케줄링이 아니라, 할당된 가중치에 따른 공정한 CPU 시간 분배입니다. CPU 집중 프로세스는 I/O 대기 시간이 없어 자연스럽게 CPU를 더 많이 사용할 수 있지만, CFS가 의도적으로 CPU 집중 프로세스를 더 자주 스케줄하는 것은 아니다.
따라서 문제 27의 정답은 ④번입니다.
문제 28 해설
문제에서는 고정된 타임 슬라이스를 사용하는 RR 스케줄러와 달리, 리눅스의 CFS는 실행 가능한 프로세스 수가 변경될 때마다 목표 지연 시간과 그에 따른 프로세스별 할당 시간을 재계산하는 이유를 묻고 있음
CFS가 실행 가능한 프로세스 수 변화에 따라 목표 지연 시간과 할당 시간을 동적으로 조정하는 이유는 공정성을 유지하기 위해서이다.
 * RR 스케줄러의 고정된 타임 슬라이스: 단순한 RR 스케줄러에서 실행 가능한 프로세스 수가 증가하면, 각 프로세스는 정해진 시간 동안 CPU를 번갈아 사용하지만, 전체 CPU 시간에서 각 프로세스가 차지하는 비율은 줄어들어 응답성이 저하될 수 있다. 특히 대화형 작업의 경우 사용자 경험에 부정적인 영향을 미칠 수 있다.
 * CFS의 동적 조정: CFS는 각 프로세스에 공정한 CPU 점유율을 제공하는 것을 목표로 한다. 이를 위해 다음과 같은 방식을 사용한다.
   * 목표 지연 시간(target latency) 설정: 모든 실행 가능한 프로세스가 최소한 짧은 시간이라도 CPU를 할당받아야 하는 이상적인 시간 창이다.
   * 프로세스별 목표 할당 시간 계산: 목표 지연 시간과 프로세스의 가중치(우선순위)를 기반으로 각 프로세스가 할당받을 목표 시간을 계산한다. 높은 가중치를 가진 프로세스는 더 긴 할당 시간을 받는다.
   * 목표 지연 시간의 동적 조정: 실행 가능한 프로세스 수가 증가하면 CFS는 일반적으로 목표 지연 시간을 늘린다. 이렇게 하면 프로세스 수가 많아지더라도 각 프로세스가 최소한의 실행 시간을 보장받아 CPU 시간 조각화가 심해지는 것을 막고 응답성을 유지할 수 있다. 반대로 실행 가능한 프로세스 수가 감소하면 목표 지연 시간을 줄일 수 있다.
결론적으로 CFS는 실행 가능한 프로세스 수가 변하더라도 공정성을 유지하고 시스템 응답성을 최적화하기 위해 목표 지연 시간과 할당 시간을 재계산한다. 이는 작업 부하 변화에 따라 고정된 타임 슬라이스를 사용하는 RR 스케줄러에서 발생할 수 있는 응답성 저하 문제를 해결한다.
CFS(Completely Fair Scheduling)의 필요성
CFS는 이전 리눅스 스케줄러의 한계를 극복하고 CPU 자원을 보다 강력하고 공정하게 관리하기 위해 리눅스 커널에 도입되었다. CFS가 필요한 이유는 다음과 같다.
 * 공정성: 이름에서 알 수 있듯이 CFS의 핵심 원칙은 공정성이다. 각 실행 가능한 프로세스에 할당된 가중치(우선순위)에 따라 CPU 시간을 공정하게 분배하여 특정 프로세스가 CPU를 독점하는 것을 방지하고 모든 프로세스가 진척도를 보장받도록 한다.
 * 응답성: 목표 지연 시간과 할당 시간을 동적으로 조정함으로써 CFS는 특히 대화형 작업에서 우수한 시스템 응답성을 유지하는 데 도움을 준다. 시스템 부하가 높은 상황에서도 대화형 애플리케이션은 충분한 CPU 시간을 할당받아 사용자가 쾌적하게 느낄 수 있도록 한다.
 * 다양한 우선순위 처리: CFS는 가중치를 사용하여 프로세스 우선순위를 나타낸다. 이를 통해 낮은 우선순위 프로세스를 완전히 배제하지 않으면서 높은 우선순위 프로세스에 더 많은 CPU 시간을 비례적으로 할당할 수 있다.
 * 기아 현상 방지: 가상 실행 시간을 추적하고 항상 가장 작은 가상 실행 시간을 가진 프로세스를 다음에 실행하도록 선택하는 CFS의 설계는 본질적으로 프로세스 기아 현상을 방지한다. 모든 실행 가능한 프로세스는 결국 실행 기회를 얻게 된다.
 * 확장성: CFS는 많은 수의 프로세스를 효율적으로 관리할 수 있도록 설계되어 확장성이 뛰어나다. 스케줄링 결정 알고리즘이 비교적 효율적이다.
 * 복잡성 관리: CFS의 내부 메커니즘은 복잡하지만, 이전 스케줄러에 비해 수동 튜닝의 필요성이 적다. 동적인 조정 기능은 시스템이 변화하는 작업 부하에 자동으로 적응하도록 돕는다.
요약하자면, CFS는 현대 운영체제인 리눅스에서 보다 균형 잡히고 효율적인 CPU 스케줄링 방식을 제공하여 공정성, 응답성을 보장하고 특히 다양하고 동적인 컴퓨팅 환경에서 기아 현상과 같은 문제를 예방한다.
